{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1626061355643,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "siMpwITBI_fM"
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "## Numpy/PyTorch implementation of Poisson Inverse Gaussian Distribution\n",
    "## See: https://github.com/cran/gamlss.dist\n",
    "## See (count distributions - page197): http://www.gamlss.com/wp-content/uploads/2013/01/gamlss-manual.pdf \n",
    "##\n",
    "## Author: Chris Meaney\n",
    "## Date: August 2021\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3998,
     "status": "ok",
     "timestamp": 1626061359965,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "E4ozfC7PJCqf"
   },
   "outputs": [],
   "source": [
    "## Dependency modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.special import gammaln\n",
    "from sinfo import sinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "executionInfo": {
     "elapsed": 22643,
     "status": "ok",
     "timestamp": 1626061382604,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "wFUABrptfuuu",
    "outputId": "9b5d096e-a385-4108-c72f-5c04f0c3260d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fish</th>\n",
       "      <th>lake</th>\n",
       "      <th>x</th>\n",
       "      <th>scale_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>-1.533430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>-0.901903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>171</td>\n",
       "      <td>5.141664</td>\n",
       "      <td>-0.473281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113</td>\n",
       "      <td>25719</td>\n",
       "      <td>10.154985</td>\n",
       "      <td>1.031399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>59596</td>\n",
       "      <td>10.995344</td>\n",
       "      <td>1.283621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.016481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>-0.880708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114</td>\n",
       "      <td>58016</td>\n",
       "      <td>10.968474</td>\n",
       "      <td>1.275556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>112</td>\n",
       "      <td>19477</td>\n",
       "      <td>9.876990</td>\n",
       "      <td>0.947962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>-1.325392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>-0.683080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.016481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39</td>\n",
       "      <td>174</td>\n",
       "      <td>5.159055</td>\n",
       "      <td>-0.468061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>-1.686748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>3.988984</td>\n",
       "      <td>-0.819242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fish   lake          x   scale_x\n",
       "0     10      5   1.609438 -1.533430\n",
       "1     37     41   3.713572 -0.901903\n",
       "2     60    171   5.141664 -0.473281\n",
       "3    113  25719  10.154985  1.031399\n",
       "4     99  59596  10.995344  1.283621\n",
       "5     13      1   0.000000 -2.016481\n",
       "6     30     44   3.784190 -0.880708\n",
       "7    114  58016  10.968474  1.275556\n",
       "8    112  19477   9.876990  0.947962\n",
       "9     17     10   2.302585 -1.325392\n",
       "10    10     85   4.442651 -0.683080\n",
       "11    14      1   0.000000 -2.016481\n",
       "12    39    174   5.159055 -0.468061\n",
       "13    14      3   1.098612 -1.686748\n",
       "14    14     54   3.988984 -0.819242"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################################\n",
    "## Use pandas to import data, and store as DataFrame\n",
    "## Data are 1) response/target variable (number of fish = count random variable), 2) lake size (single continous feature/predictor)\n",
    "##########################################################\n",
    "dat = pd.read_csv('C://Users//ChristopherMeaney//Desktop//PyTorch_Stuff//pytorch_count_dists//species.csv', encoding='latin1')\n",
    "dat.head(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1626061382606,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "5-Hzlh2yJCvy",
    "outputId": "211689d5-e4ef-4c31-9aaa-25f0f8ef16ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     70.000000\n",
       "mean      41.742857\n",
       "std       47.849609\n",
       "min        5.000000\n",
       "25%       14.000000\n",
       "50%       21.500000\n",
       "75%       47.500000\n",
       "max      245.000000\n",
       "Name: fish, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Describe the data\n",
    "dat.fish.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.74285714285714"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_ = dat.fish.mean()\n",
    "mu_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.84960912241293"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_ = np.sqrt(dat.fish.var())\n",
    "sigma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1626061382607,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "TjFl0euzh5Vv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        , -1.40546511, -1.99325177, -2.54181772, -3.0204051 ,\n",
       "       -3.43882735, -3.81108203, -4.14828042, -4.45842434, -4.74722951])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################\n",
    "## Numpy implementation of Poisson Inverse Gaussian Loss/Density Function\n",
    "## Function is basically a Numpy implementation of Rigby et al gamlss.dist R Code (which calls tofyPIG2.c)\n",
    "## https://github.com/cran/gamlss.dist/tree/master/src/tofyPIG2.c\n",
    "###################################################\n",
    "def d_PIG_np(x, mu=1, sigma=1, log=True): \n",
    "    ## Determine length of data vector and parameters \n",
    "    ly = np.max(np.array([len(x), len(mu), len(sigma)]))  \n",
    "    #x = np.repeat(a=x, repeats=ly)      \n",
    "    nsigma = np.repeat(a=sigma, repeats=ly)\n",
    "    nmu = np.repeat(a=mu, repeats=ly)\n",
    "    ## Initial vectors to store computed PIG density values\n",
    "    ny = int(len(x))\n",
    "    maxyp1 = np.max(x) + 1\n",
    "    tofY = np.zeros(shape=(maxyp1))\n",
    "    sumlty = np.zeros(shape=(ly))\n",
    "    ## Big for loop to compute PIG density (or log-density)\n",
    "    ## This is directly from Rigby et al: tofyPIG2.c code.\n",
    "    for i in range(1, ny+1):\n",
    "        iy = x[i-1] + 1\n",
    "        tofY[0] = nmu[i-1] * ((1 + 2*nsigma[i-1]*nmu[i-1])**(-0.5))\n",
    "        sumT = 0 \n",
    "        ## Start inner loop to compute rest of PIG density\n",
    "        if (x[i-1]==0):\n",
    "            sumT = 0\n",
    "        else:\n",
    "            for j in range(1, iy):\n",
    "                tofY[j] = ((nsigma[i-1] * ((2*(j)-1)/nmu[i-1])) + (1/tofY[j-1])) * ((tofY[0])**2)\n",
    "                sumT = sumT + np.log(tofY[j-1])\n",
    "        sumlty[i-1] = sumT\n",
    "    ## Add the kernel of the PIG density back to other constant component\n",
    "    logfy = -gammaln(x+1) + (1 - np.sqrt(1 + 2*sigma*mu))/sigma + sumlty\n",
    "    ## log={T,F} flag: T=return log-density; F=return density\n",
    "    if(log==False):\n",
    "        fy = np.exp(logfy)\n",
    "    else:\n",
    "        fy = logfy\n",
    "    ## Return log density function to user\n",
    "    return fy\n",
    "\n",
    "d_PIG_np(x=np.arange(10), mu=np.array([2]), sigma=np.array([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000, -1.4055, -1.9933, -2.5418, -3.0204, -3.4388, -3.8111, -4.1483,\n",
       "        -4.4584, -4.7472])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################\n",
    "## PyTorch implementation of Poisson Inverse Gaussian Loss/Density Function\n",
    "## Function is basically a Numpy implementation of Rigby et al gamlss.dist R Code (which calls tofyPIG2.c)\n",
    "## https://github.com/cran/gamlss.dist/tree/master/src/tofyPIG2.c\n",
    "###################################################\n",
    "def d_PIG_th(x, mu, sigma): \n",
    "    ## Determine length of data vector and parameters \n",
    "    ly = int(torch.max(torch.Tensor([len(x), len(mu), len(sigma)])).item())\n",
    "    #x = np.repeat(a=x, repeats=ly)      \n",
    "    nsigma = sigma.repeat(ly)\n",
    "    nmu = mu.repeat(ly)\n",
    "    ## Initial vectors to store computed PIG density values\n",
    "    ny = int(len(x))\n",
    "    maxyp1 = torch.max(x) + 1\n",
    "    tofY = torch.zeros(maxyp1)\n",
    "    sumlty = torch.zeros(ly)\n",
    "    ## Big for loop to compute PIG density (or log-density)\n",
    "    ## This is directly from Rigby et al: tofyPIG2.c code.\n",
    "    for i in torch.arange(1, ny+1):\n",
    "        iy = x[i.item()-1] + 1\n",
    "        tofY[0] = nmu[i.item()-1] * ((1 + 2*nsigma[i.item()-1]*nmu[i.item()-1])**(-0.5))\n",
    "        sumT = torch.Tensor([0]) \n",
    "        ## Start inner loop to compute rest of PIG density\n",
    "        if (x[i.item()-1]==0):\n",
    "            sumT = torch.Tensor([0])\n",
    "        else:\n",
    "            for j in torch.arange(1, iy):\n",
    "                tofY[j.item()] = ((nsigma[i.item()-1] * ((2*(j.item())-1)/nmu[i.item()-1])) + (1/tofY[j.item()-1])) * ((tofY[0])**2)\n",
    "                sumT = sumT + np.log(tofY[j.item()-1])\n",
    "        sumlty[i.item()-1] = sumT\n",
    "    ## Add the kernel of the PIG density back to other constant component\n",
    "    logfy = -torch.lgamma(x+1) + (1 - torch.sqrt(1 + 2*sigma*mu))/sigma + sumlty\n",
    "    ## Return log density function to user\n",
    "    return logfy\n",
    "\n",
    "d_PIG_th(x=torch.arange(10), mu=torch.Tensor([2]), sigma=torch.Tensor([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WARNING: read me... \n",
    "## Below is user-defined R implementation of PIG (Poisson Inverse Gaussian) density\n",
    "## We also compare against gamlss.dist::dPIG() code rolled out in gamlss.dist package\n",
    "## Documentation on page 197: http://www.gamlss.com/wp-content/uploads/2013/01/gamlss-manual.pdf\n",
    "## You will see that above Numpy and PyTorch implementations agree with R output (up to many decimal places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "> library(gamlss.dist)\n",
    ">\n",
    "> ###################################################\n",
    "> ## User-defined R code for PIG (Poisson Inverse Gaussian) Distribution\n",
    "> ###################################################\n",
    "> d_PIG <- function(x, mu=1, sigma=1 , log=FALSE) { \n",
    "+ ## Warning messages on paramter and data space constraint violations\n",
    "+     if (any(mu <= 0) )  stop(paste(\"mu must be greater than 0 \", \"\\n\", \"\")) \n",
    "+     if (any(sigma <= 0) )  stop(paste(\"sigma must be greater than 0 \", \"\\n\", \"\")) \n",
    "+     if (any(x < 0) )  stop(paste(\"x must be >=0\", \"\\n\", \"\"))  \n",
    "+     ## Determine length of data vector and parameters \n",
    "+     ly <- max(length(x), length(mu), length(sigma)) \n",
    "+     x <- rep(x, length=ly)      \n",
    "+     nsigma <- rep(sigma, length=ly)\n",
    "+     nmu <- rep(mu, length=ly)\n",
    "+     ## Initial vectors to store computed PIG density values\n",
    "+     ny <- as.integer(length(x))\n",
    "+     maxyp1 <- max(x) + 1\n",
    "+     tofY <- rep(NA_real_, maxyp1)\n",
    "+     sumlty <- rep(NA_real_, ly)\n",
    "+     ## Big for loop to compute PIG density (or log-density)\n",
    "+     ## This is directly from Rigby et al: tofyPIG2.c code.\n",
    "+     ## I **think** it looks like its implementing recursive mixed-Pois prob calc\n",
    "+     ## This is likely why (for large vectors, with large counts) that is done in C\n",
    "+     for (i in 1:ny) {\n",
    "+     iy <- x[i] + 1\n",
    "+     tofY[1] <- nmu[i] * ((1 + 2*nsigma[i]*nmu[i])^(-0.5))\n",
    "+     sumT <- 0 \n",
    "+     ## Start inner loop to compute rest of PIG density\n",
    "+     if (x[i]==0) {\n",
    "+     sumT <- 0\n",
    "+     } else {\n",
    "+     for (j in 1:(iy-1)) {\n",
    "+     tofY[j + 1] <- ((nsigma[i] * ((2*(j)-1)/nmu[i])) + (1/tofY[j])) * ((tofY[1])^2)\n",
    "+     sumT <- sumT + log(tofY[j])\n",
    "+     }\n",
    "+     }\n",
    "+     sumlty[i] <- sumT\n",
    "+     }\n",
    "+     ## Add the kernel of the PIG density back to other constant component\n",
    "+     logfy <- -lgamma(x+1) + (1 - sqrt(1 + 2*sigma*mu))/sigma + sumlty\n",
    "+     ## log={T,F} flag: T=return log-density; F=return density\n",
    "+     if(log==FALSE) {\n",
    "+     fy <- exp(logfy)\n",
    "+     } else {\n",
    "+     fy <- logfy\n",
    "+     }\n",
    "+     ## Return log density function to user\n",
    "+     return(fy)\n",
    "+ }\n",
    " \n",
    "## User defined R implementation of PIG distribution\n",
    "> d_PIG(x=0:9, mu=2, sigma=2, log=TRUE)\n",
    " [1] -1.000000 -1.405465 -1.993252 -2.541818 -3.020405 -3.438827 -3.811082 -4.148280 -4.458424 -4.747230\n",
    "\n",
    "## gamlss.dist implementation of PIG distribution\n",
    "> dPIG(x=0:9, mu=2, sigma=2, log=TRUE)\n",
    " [1] -1.000000 -1.405465 -1.993252 -2.541818 -3.020405 -3.438827 -3.811082 -4.148280 -4.458424 -4.747230 \n",
    "'''\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1626061408611,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "t3dvWeX3iUgR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JnSaWekcwDgo"
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "## PIG Model - try to learn MLE of fish count data; via AutoGrad/SGD implementation in PyTorch\n",
    "############################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nq4R0s7zwDkI"
   },
   "outputs": [],
   "source": [
    "## Instantiate data tensor, and variable for (binomial) model parameters\n",
    "x = torch.autograd.Variable(torch.from_numpy(dat.fish.to_numpy())).type(torch.FloatTensor)\n",
    "l_mu = torch.autograd.Variable(torch.rand(1), requires_grad=True)\n",
    "l_sigma = torch.autograd.Variable(torch.rand(1), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "R93ZSIclwDmq"
   },
   "outputs": [],
   "source": [
    "def pig_nll(x, mu, sigma): \n",
    "    ## Determine length of data vector and parameters \n",
    "    ly = int(torch.max(torch.Tensor([len(x), len(mu), len(sigma)])).item())\n",
    "    #x = np.repeat(a=x, repeats=ly)      \n",
    "    nsigma = sigma.repeat(ly)\n",
    "    nmu = mu.repeat(ly)\n",
    "    ## Initial vectors to store computed PIG density values\n",
    "    ny = int(len(x))\n",
    "    maxyp1 = x.max().item() + 1\n",
    "    tofY = torch.zeros(int(maxyp1))\n",
    "    sumlty = torch.zeros(ly)\n",
    "    ## Big for loop to compute PIG density (or log-density)\n",
    "    ## This is directly from Rigby et al: tofyPIG2.c code.\n",
    "    ## I **think** it looks like its implementing recursive mixed-Pois prob calc\n",
    "    ## This is likely why (for large vectors, with large counts) that is done in C\n",
    "    for i in torch.arange(1, ny+1, dtype=torch.int32):\n",
    "        iy = x[i.item()-1] + 1\n",
    "        tofY[0] = nmu[i.item()-1] * ((1 + 2*nsigma[i.item()-1]*nmu[i.item()-1])**(-0.5))\n",
    "        sumT = torch.Tensor([0]) \n",
    "        ## Start inner loop to compute rest of PIG density\n",
    "        if (x[i.item()-1]==0):\n",
    "            sumT = torch.Tensor([0])\n",
    "        else:\n",
    "            for j in torch.arange(1, iy, dtype=torch.int32):\n",
    "                tofY[j.item()] = ((nsigma[i.item()-1] * ((2*(j.item())-1)/nmu[i.item()-1])) + (1/tofY[j.item()-1])) * ((tofY[0])**2)\n",
    "                sumT = sumT + torch.log(tofY[j.item()-1])\n",
    "        sumlty[i.item()-1] = sumT\n",
    "    ## Add the kernel of the PIG density back to other constant component\n",
    "    logfy = -torch.lgamma(x+1) + (1 - torch.sqrt(1 + 2*sigma*mu))/sigma + sumlty\n",
    "    ## Return neg log lik to user\n",
    "    nll = -torch.sum(logfy)\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9M2nPfBZwR0h"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of SelectBackward, is at version 2992; expected version 2991 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-15d640d81abc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m## Backprop on negative log likelihood loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mNLLpig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpig_nll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml_mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml_sigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mNLLpig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m## Logging to console\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of SelectBackward, is at version 2992; expected version 2991 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "## Learning rate\n",
    "learning_rate_mu = 2e-5\n",
    "learning_rate_sigma = 2e-5\n",
    "\n",
    "## Training loop\n",
    "for t in range(25000):\n",
    "    ## Backprop on negative log likelihood loss\n",
    "    NLLpig = pig_nll(x=x, mu=l_mu, sigma=l_sigma) \n",
    "    NLLpig.backward()\n",
    "    ## Logging to console\n",
    "    if t % 1000 == 0:\n",
    "        print(\"Iteration = \", t, \n",
    "              \"loglik  =\", NLLpig.data.numpy(), \n",
    "              \"lmu =\", l_mu.data.numpy(), \n",
    "              \"lsigma =\", l_sigma.data.numpy(),  \n",
    "              \"dL/dlmu = \", l_mu.grad.data.numpy(), \n",
    "              \"dL/dlsigma = \", l_sigma.grad.data.numpy())\n",
    "    ## SGD update of parms\n",
    "    l_mu.data -= learning_rate_mu * l_mu.grad.data\n",
    "    l_sigma.data -= learning_rate_sigma * l_sigma.grad.data\n",
    "    ## Zero the gradients\n",
    "    l_mu.grad.data.zero_()\n",
    "    l_sigma.grad.data.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENmhqPFPwEHS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "numpy       1.20.3\n",
      "pandas      1.3.1\n",
      "sinfo       0.3.1\n",
      "torch       1.9.0\n",
      "-----\n",
      "IPython             7.26.0\n",
      "jupyter_client      6.1.12\n",
      "jupyter_core        4.7.1\n",
      "jupyterlab          3.1.7\n",
      "notebook            6.4.3\n",
      "-----\n",
      "Python 3.9.6 (default, Aug 18 2021, 15:44:49) [MSC v.1916 64 bit (AMD64)]\n",
      "Windows-10-10.0.19042-SP0\n",
      "8 logical CPU cores, Intel64 Family 6 Model 126 Stepping 5, GenuineIntel\n",
      "-----\n",
      "Session information updated at 2021-08-20 16:51\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "## Print session info to console \n",
    "########################\n",
    "sinfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP+Y2qdOHz9LLr9FTwsBagp",
   "collapsed_sections": [],
   "name": "PyTorch_CountDistMLEs_SpeciesDatasetExample.ipynb",
   "provenance": [
    {
     "file_id": "1XRwZ_jQyySdAa4a4jZ7VwYuLWtRaz4f2",
     "timestamp": 1625988939591
    },
    {
     "file_id": "1Q-GUXkWcqMJjpF_OgecQBUA7ZEGBLkXw",
     "timestamp": 1625986377347
    },
    {
     "file_id": "1UVQOt_noxCtpcDVvyBz6GPuDTD3XPTCZ",
     "timestamp": 1625983790664
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
