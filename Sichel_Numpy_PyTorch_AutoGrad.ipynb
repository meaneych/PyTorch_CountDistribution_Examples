{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1626061355643,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "siMpwITBI_fM"
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "## Numpy/PyTorch implementation of Sichel Distribution\n",
    "## See: https://github.com/cran/gamlss.dist\n",
    "## See (count distributions - page197): http://www.gamlss.com/wp-content/uploads/2013/01/gamlss-manual.pdf \n",
    "##\n",
    "## Author: Chris Meaney\n",
    "## Date: August 2021\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3998,
     "status": "ok",
     "timestamp": 1626061359965,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "E4ozfC7PJCqf"
   },
   "outputs": [],
   "source": [
    "## Dependency modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.special import gammaln\n",
    "from scipy.special import kv\n",
    "from sinfo import sinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "executionInfo": {
     "elapsed": 22643,
     "status": "ok",
     "timestamp": 1626061382604,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "wFUABrptfuuu",
    "outputId": "9b5d096e-a385-4108-c72f-5c04f0c3260d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fish</th>\n",
       "      <th>lake</th>\n",
       "      <th>x</th>\n",
       "      <th>scale_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>-1.533430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>-0.901903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>171</td>\n",
       "      <td>5.141664</td>\n",
       "      <td>-0.473281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113</td>\n",
       "      <td>25719</td>\n",
       "      <td>10.154985</td>\n",
       "      <td>1.031399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>59596</td>\n",
       "      <td>10.995344</td>\n",
       "      <td>1.283621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.016481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>-0.880708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114</td>\n",
       "      <td>58016</td>\n",
       "      <td>10.968474</td>\n",
       "      <td>1.275556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>112</td>\n",
       "      <td>19477</td>\n",
       "      <td>9.876990</td>\n",
       "      <td>0.947962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>-1.325392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>-0.683080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.016481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39</td>\n",
       "      <td>174</td>\n",
       "      <td>5.159055</td>\n",
       "      <td>-0.468061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>-1.686748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>3.988984</td>\n",
       "      <td>-0.819242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fish   lake          x   scale_x\n",
       "0     10      5   1.609438 -1.533430\n",
       "1     37     41   3.713572 -0.901903\n",
       "2     60    171   5.141664 -0.473281\n",
       "3    113  25719  10.154985  1.031399\n",
       "4     99  59596  10.995344  1.283621\n",
       "5     13      1   0.000000 -2.016481\n",
       "6     30     44   3.784190 -0.880708\n",
       "7    114  58016  10.968474  1.275556\n",
       "8    112  19477   9.876990  0.947962\n",
       "9     17     10   2.302585 -1.325392\n",
       "10    10     85   4.442651 -0.683080\n",
       "11    14      1   0.000000 -2.016481\n",
       "12    39    174   5.159055 -0.468061\n",
       "13    14      3   1.098612 -1.686748\n",
       "14    14     54   3.988984 -0.819242"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################################\n",
    "## Use pandas to import data, and store as DataFrame\n",
    "## Data are 1) response/target variable (number of fish = count random variable), 2) lake size (single continous feature/predictor)\n",
    "##########################################################\n",
    "dat = pd.read_csv('C://Users//ChristopherMeaney//Desktop//PyTorch_Stuff//pytorch_count_dists//species.csv', encoding='latin1')\n",
    "dat.head(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1626061382606,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "5-Hzlh2yJCvy",
    "outputId": "211689d5-e4ef-4c31-9aaa-25f0f8ef16ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     70.000000\n",
       "mean      41.742857\n",
       "std       47.849609\n",
       "min        5.000000\n",
       "25%       14.000000\n",
       "50%       21.500000\n",
       "75%       47.500000\n",
       "max      245.000000\n",
       "Name: fish, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Describe the data\n",
    "dat.fish.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.74285714285714"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_ = dat.fish.mean()\n",
    "mu_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.84960912241293"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_ = np.sqrt(dat.fish.var())\n",
    "sigma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1626061382607,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "TjFl0euzh5Vv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.73205081, -1.28135695, -2.06806388, -2.85477081, -3.59360409,\n",
       "       -4.28363973, -4.93343401, -5.55145683, -6.14437891, -6.71720088])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################\n",
    "## Numpy implementation of Sichel Loss/Density Function\n",
    "## Function is basically a Numpy implementation of Rigby et al gamlss.dist R Code (which calls tofySICHEL2.c)\n",
    "## https://github.com/cran/gamlss.dist/tree/master/src/tofySICHEL2.c\n",
    "###################################################\n",
    "def d_SICHEL_np(x, mu, sigma, nu, log=True):\n",
    "    ## Determine length of data vector and parameters \n",
    "    ly = np.max(np.array([len(x), len(mu), len(sigma), len(nu)]))  \n",
    "    #x = np.repeat(a=x, repeats=ly)      \n",
    "    nsigma = np.repeat(a=sigma, repeats=ly)\n",
    "    nmu = np.repeat(a=mu, repeats=ly)\n",
    "    nnu = np.repeat(a=nu, repeats=ly)\n",
    "    ## Global constants in SICHEL density     \n",
    "    cvec = np.exp(np.log(kv(nnu + 1, (1/nsigma))) - np.log(kv(nnu, (1/nsigma))))\n",
    "    alpha = np.sqrt(1 + 2*nsigma * (nmu/cvec))/nsigma\n",
    "    lbes = np.log(kv(nnu + 1, alpha)) - np.log(kv(nnu, alpha))\n",
    "    ## Initial vectors to store computed SICHEL density values\n",
    "    ny = int(len(x))\n",
    "    maxyp1 = np.max(x) + 1\n",
    "    tofY = np.zeros(shape=(maxyp1))\n",
    "    sumlty = np.zeros(shape=(ly))\n",
    "    ## Big for loop to compute SICHEL density (or log-density)\n",
    "    ## This is directly from Rigby et al: tofySICHEL2.c code.\n",
    "    for i in range(1, ny+1):\n",
    "        iy = x[i-1] + 1\n",
    "        tofY[0] = (nmu[i-1]/cvec[i-1]) * np.power(1 + 2*nsigma[i-1]*(nmu[i-1]/cvec[i-1]), -1/2) * np.exp(lbes[i-1]) \n",
    "        alpha = np.sqrt(1 + 2*nsigma[i-1]*(nmu[i-1]/cvec[i-1]))/nsigma[i-1]\n",
    "        sumT = 0 \n",
    "        ## Start inner loop to compute rest of SICHEL density\n",
    "        if (x[i-1]==0):\n",
    "            sumT = 0\n",
    "        else:\n",
    "            for j in range(1, iy):\n",
    "                tofY[j] = ( (cvec[i-1]*nsigma[i-1] * (2*(j+nnu[i-1])/nmu[i-1])) + (1/tofY[j-1])) * np.power(nmu[i-1]/(nsigma[i-1]*alpha*cvec[i-1]), 2)\n",
    "                sumT = sumT + np.log(tofY[j-1])\n",
    "        sumlty[i-1] = sumT\n",
    "    ## Add the kernel of the SICHEL density back to other constant component\n",
    "    logfy = -gammaln(x+1) - nnu*np.log(nsigma * alpha) + sumlty + np.log(kv(nnu, alpha)) - np.log(kv(nnu, (1/nsigma)))\n",
    "    ## Log={T,F} flag: T=return log-density; F=return density\n",
    "    if(log==False):\n",
    "        fy = np.exp(logfy)  \n",
    "    else:\n",
    "        fy = logfy\n",
    "    ## If sigma>10000 (large) AND nu>0 then can approx. SICHEL using NBI\n",
    "    # fy <- ifelse((nsigma>10000)&(nnu>0), dnbinom(x, size=abs(nnu), mu=nmu, log=log), fy)\n",
    "    ## Return log-density (or density) to user\n",
    "    return fy\n",
    "\n",
    "d_SICHEL_np(x=np.arange(10), mu=np.array([1]), sigma=np.array([1]), nu=np.array([-0.5]), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WARNING: below is NOT a pure PyTorch implementation of SICHEL density/distribution\n",
    "## ISSUE: PyTorch and torch.special does NOT have implementation of BESSEL functions\n",
    "## WORKAROUND: we roll a PyTorch implementation where possible; however, default back to scipy.special.kv() where needed\n",
    "## ISSUE: since it is NOT a pure PyTorch implementation we CANNOT run AutoGrad/BackProp/etc. on this loss (due to detach of values/nodes from computational graph)\n",
    "## WORKAROUND: I am going to **try** to roll something like torch.special.kv()...will need to test/go-slow (since limitted experience with this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7321, -1.2814, -2.0681, -2.8548, -3.5936, -4.2836, -4.9334, -5.5515,\n",
       "        -6.1444, -6.7172])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################\n",
    "## PyTorch implementation of SICHEL Loss/Density Function\n",
    "## Function is basically a Numpy implementation of Rigby et al gamlss.dist R Code (which calls tofySICHEL2.c)\n",
    "## https://github.com/cran/gamlss.dist/tree/master/src/tofySICHEL2.c\n",
    "###################################################\n",
    "def d_PIG_th(x, mu, sigma, nu, log=True): \n",
    "    ## Determine length of data vector and parameters \n",
    "    ly = int(torch.max(torch.Tensor([len(x), len(mu), len(sigma)])).item())\n",
    "    #x = np.repeat(a=x, repeats=ly)      \n",
    "    nsigma = sigma.repeat(ly)\n",
    "    nmu = mu.repeat(ly)\n",
    "    nnu = nu.repeat(ly)\n",
    "    ## Global constants in SICHEL density     \n",
    "    cvec = torch.exp(torch.log(kv(nnu + 1, (1/nsigma))) - torch.log(kv(nnu, (1/nsigma))))\n",
    "    alpha = torch.sqrt(1 + 2*nsigma * (nmu/cvec))/nsigma\n",
    "    lbes = torch.log(kv(nnu + 1, alpha)) - torch.log(kv(nnu, alpha))\n",
    "    ## Initial vectors to store computed PIG density values\n",
    "    ny = int(len(x))\n",
    "    maxyp1 = torch.max(x) + 1\n",
    "    tofY = torch.zeros(maxyp1)\n",
    "    sumlty = torch.zeros(ly)\n",
    "    ## Big for loop to compute SICHEL density (or log-density)\n",
    "    ## This is directly from Rigby et al: tofySICHEL2.c code.\n",
    "    for i in torch.arange(1, ny+1):\n",
    "        iy = x[i.item()-1] + 1\n",
    "        tofY[0] = (nmu[i.item()-1]/cvec[i.item()-1]) * torch.pow(1 + 2*nsigma[i.item()-1]*(nmu[i.item()-1]/cvec[i.item()-1]), -1/2) * torch.exp(lbes[i.item()-1]) \n",
    "        alpha = torch.sqrt(1 + 2*nsigma[i.item()-1]*(nmu[i.item()-1]/cvec[i.item()-1]))/nsigma[i.item()-1]\n",
    "        sumT = 0 \n",
    "        ## Start inner loop to compute rest of SICHEL density\n",
    "        if (x[i.item()-1]==0):\n",
    "            sumT = 0\n",
    "        else:\n",
    "            for j in torch.arange(1, iy):\n",
    "                tofY[j.item()] = ( (cvec[i.item()-1]*nsigma[i.item()-1] * (2*(j.item()+nnu[i.item()-1])/nmu[i.item()-1])) + (1/tofY[j.item()-1])) * torch.pow(nmu[i.item()-1]/(nsigma[i.item()-1]*alpha*cvec[i.item()-1]), 2)\n",
    "                sumT = sumT + torch.log(tofY[j.item()-1])\n",
    "        sumlty[i.item()-1] = sumT\n",
    "    ## Add the kernel of the SICHEL density back to other constant component\n",
    "    logfy = -torch.lgamma(x+1) - nnu*torch.log(nsigma * alpha) + sumlty + torch.log(kv(nnu, alpha)) - torch.log(kv(nnu, (1/nsigma)))\n",
    "    ## Log={T,F} flag: T=return log-density; F=return density\n",
    "    if(log==False):\n",
    "        fy = torch.exp(logfy)  \n",
    "    else:\n",
    "        fy = logfy\n",
    "    ## If sigma>10000 (large) AND nu>0 then can approx. SICHEL using NBI\n",
    "    # fy <- ifelse((nsigma>10000)&(nnu>0), dnbinom(x, size=abs(nnu), mu=nmu, log=log), fy)\n",
    "    ## Return log-density (or density) to user\n",
    "    return fy\n",
    "\n",
    "d_PIG_th(x=torch.arange(10), mu=torch.Tensor([1]), sigma=torch.Tensor([1]), nu=torch.Tensor([-0.5]), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WARNING: read me... \n",
    "## Below is user-defined R implementation of SICHEL density\n",
    "## We also compare against gamlss.dist::dSICHEL() code rolled out in gamlss.dist package\n",
    "## Documentation on page 197: http://www.gamlss.com/wp-content/uploads/2013/01/gamlss-manual.pdf\n",
    "## You will see that above Numpy and PyTorch implementations agree with R implementation up to many decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "> \n",
    "> library(gamlss.dist)\n",
    "> \n",
    "> d_SICHEL<-function(x, mu=1, sigma=1, nu=-0.5, log=FALSE) { \n",
    "+     ## Warning messages on paramter and data space constraint violations\n",
    "+     if (any(mu <= 0) )  stop(paste(\"mu must be greater than 0 \", \"\\n\", \"\")) \n",
    "+     if (any(sigma <= 0) )  stop(paste(\"sigma must be greater than 0 \", \"\\n\", \"\")) \n",
    "+     if (any(x < 0) )  stop(paste(\"x must be >=0\", \"\\n\", \"\"))  \n",
    "+     ## Determine length of data vector and parameters \n",
    "+     ly <- max(length(x),length(mu),length(sigma),length(nu))\n",
    "+     x <- rep(x, length = ly)      \n",
    "+     nsigma <- rep(sigma, length = ly)\n",
    "+     nmu <- rep(mu, length = ly)   \n",
    "+     nnu <- rep(nu, length = ly)\n",
    "+     ## Global constants in SICHEL density     \n",
    "+     cvec <- exp(log(besselK((1/nsigma), nnu + 1)) - log(besselK((1/nsigma), nnu)))\n",
    "+     alpha <- sqrt(1 + 2*nsigma * (nmu/cvec))/nsigma\n",
    "+     lbes <- log(besselK(alpha, nnu + 1)) - log(besselK((alpha), nnu))\n",
    "+     ## Initial vectors to store computed PIG density values\n",
    "+     ny <- as.integer(length(x))\n",
    "+     maxyp1 <- max(x) + 1\n",
    "+     tofY <- rep(NA_real_, maxyp1)\n",
    "+     sumlty <- rep(NA_real_, ly)\n",
    "+     ## Big for loop to compute SICHEL density (or log-density)\n",
    "+     ## This is directly from Rigby et al: tofySICHEL2.c code.\n",
    "+     ## I **think** it looks like its implementing recursive mixed-Pois prob calc\n",
    "+     ## This is likely why (for large vectors, with large counts) that is done in C\n",
    "+     for (i in 1:ny) {\n",
    "+         iy <- x[i] + 1\n",
    "+         tofY[1] <- (nmu[i]/cvec[i]) * (1 + 2*nsigma[i]*(nmu[i]/cvec[i]))^(-1/2) * exp(lbes[i]) \n",
    "+         alpha = sqrt(1 + 2*nsigma[i]*(nmu[i]/cvec[i]))/nsigma[i]\n",
    "+         sumT <- 0 \n",
    "+         ## Start inner loop to compute rest of PIG density\n",
    "+         if (x[i]==0) {\n",
    "+             sumT <- 0\n",
    "+         } else {\n",
    "+             for (j in 1:(iy-1)) {\n",
    "+                 tofY[j + 1] <- ( (cvec[i]*nsigma[i] * (2*(j+nnu[i])/nmu[i])) + (1/tofY[j])) * (nmu[i]/(nsigma[i]*alpha*cvec[i]))^2\n",
    "+                 sumT <- sumT + log(tofY[j])\n",
    "+             }\n",
    "+         }\n",
    "+         sumlty[i] <- sumT\n",
    "+     }\n",
    "+     ## Add the kernel of the PIG density back to other constant component\n",
    "+     logfy <- -lgamma(x+1) - nnu*log(nsigma * alpha) + sumlty + log(besselK(alpha, nnu)) - log(besselK((1/nsigma), nnu))\n",
    "+     ## Log={T,F} flag: T=return log-density; F=return density\n",
    "+     if(log==FALSE) {\n",
    "+         fy <- exp(logfy)  \n",
    "+     } else {\n",
    "+         fy <- logfy\n",
    "+     }\n",
    "+     ## If sigma>10000 (large) AND nu>0 then can approx. SICHEL using NBI\n",
    "+     fy <- ifelse((nsigma>10000)&(nnu>0), dnbinom(x, size=abs(nnu), mu=nmu, log=log), fy)\n",
    "+     ## Return log-density (or density) to user\n",
    "+     return(fy)\n",
    "+ }\n",
    " \n",
    "> d_SICHEL(x=0:9, mu=1, sigma=1, nu=-0.5, log=TRUE)\n",
    " [1] -0.7320508 -1.2813570 -2.0680639 -2.8547708 -3.5936041 -4.2836397 -4.9334340 -5.5514568 -6.1443789 -6.7172009\n",
    "\n",
    "> dSICHEL(x=0:9, mu=1, sigma=1, nu=-0.5, log=TRUE)\n",
    " [1] -0.7320508 -1.2813570 -2.0680639 -2.8547708 -3.5936041 -4.2836397 -4.9334340 -5.5514568 -6.1443789 -6.7172009\n",
    "> \n",
    "'''\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1626061408611,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "t3dvWeX3iUgR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JnSaWekcwDgo"
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "## SICHEL Model - try to learn MLE of fish count data; via AutoGrad/SGD implementation in PyTorch\n",
    "############################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nq4R0s7zwDkI"
   },
   "outputs": [],
   "source": [
    "## Instantiate data tensor, and variable for (binomial) model parameters\n",
    "x = torch.autograd.Variable(torch.from_numpy(dat.fish.to_numpy())).type(torch.FloatTensor)\n",
    "l_mu = torch.autograd.Variable(torch.rand(1), requires_grad=True)\n",
    "l_sigma = torch.autograd.Variable(torch.rand(1), requires_grad=True) \n",
    "l_nu = torch.autograd.Variable(torch.rand(1), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "R93ZSIclwDmq"
   },
   "outputs": [],
   "source": [
    "def sichel_nll(x, mu, sigma, nu): \n",
    "    ## Determine length of data vector and parameters \n",
    "    ly = int(torch.max(torch.Tensor([len(x), len(mu), len(sigma)])).item())\n",
    "    #x = np.repeat(a=x, repeats=ly)      \n",
    "    nsigma = sigma.repeat(ly)\n",
    "    nmu = mu.repeat(ly)\n",
    "    nnu = nu.repeat(ly)\n",
    "    ## Global constants in SICHEL density     \n",
    "    cvec = torch.exp(torch.log(kv(nnu + 1, (1/nsigma))) - torch.log(kv(nnu, (1/nsigma))))\n",
    "    alpha = torch.sqrt(1 + 2*nsigma * (nmu/cvec))/nsigma\n",
    "    lbes = torch.log(kv(nnu + 1, alpha)) - torch.log(kv(nnu, alpha))\n",
    "    ## Initial vectors to store computed PIG density values\n",
    "    ny = int(len(x))\n",
    "    maxyp1 = torch.max(x) + 1\n",
    "    tofY = torch.zeros(maxyp1)\n",
    "    sumlty = torch.zeros(ly)\n",
    "    ## Big for loop to compute SICHEL density (or log-density)\n",
    "    ## This is directly from Rigby et al: tofySICHEL2.c code.\n",
    "    for i in torch.arange(1, ny+1):\n",
    "        iy = x[i.item()-1] + 1\n",
    "        tofY[0] = (nmu[i.item()-1]/cvec[i.item()-1]) * torch.pow(1 + 2*nsigma[i.item()-1]*(nmu[i.item()-1]/cvec[i.item()-1]), -1/2) * torch.exp(lbes[i.item()-1]) \n",
    "        alpha = torch.sqrt(1 + 2*nsigma[i.item()-1]*(nmu[i.item()-1]/cvec[i.item()-1]))/nsigma[i.item()-1]\n",
    "        sumT = 0 \n",
    "        ## Start inner loop to compute rest of SICHEL density\n",
    "        if (x[i.item()-1]==0):\n",
    "            sumT = 0\n",
    "        else:\n",
    "            for j in torch.arange(1, iy):\n",
    "                tofY[j.item()] = ( (cvec[i.item()-1]*nsigma[i.item()-1] * (2*(j.item()+nnu[i.item()-1])/nmu[i.item()-1])) + (1/tofY[j.item()-1])) * torch.pow(nmu[i.item()-1]/(nsigma[i.item()-1]*alpha*cvec[i.item()-1]), 2)\n",
    "                sumT = sumT + torch.log(tofY[j.item()-1])\n",
    "        sumlty[i.item()-1] = sumT\n",
    "    ## Add the kernel of the SICHEL density back to other constant component\n",
    "    logfy = -torch.lgamma(x+1) - nnu*torch.log(nsigma * alpha) + sumlty + torch.log(kv(nnu, alpha)) - torch.log(kv(nnu, (1/nsigma)))\n",
    "    ## Return neg log lik to user\n",
    "    nll = -torch.sum(logfy)\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9M2nPfBZwR0h"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-788007928b38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m## Backprop on negative log likelihood loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mNLLsichel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msichel_nll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml_mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml_sigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml_nu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mNLLsichel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m## Logging to console\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-595be9f82487>\u001b[0m in \u001b[0;36msichel_nll\u001b[1;34m(x, mu, sigma, nu)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnnu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m## Global constants in SICHEL density\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnu\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnsigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnsigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnsigma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnmu\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnsigma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mlbes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnu\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "## Learning rate\n",
    "learning_rate_mu = 2e-5\n",
    "learning_rate_sigma = 2e-5\n",
    "learning_rate_nu = 2e-5\n",
    "\n",
    "## Training loop\n",
    "for t in range(25000):\n",
    "    ## Backprop on negative log likelihood loss\n",
    "    NLLsichel = sichel_nll(x=x, mu=l_mu, sigma=l_sigma, nu=l_nu) \n",
    "    NLLsichel.backward()\n",
    "    ## Logging to console\n",
    "    if t % 1000 == 0:\n",
    "        print(\"Iteration = \", t, \n",
    "              \"loglik  =\", NLLpig.data.numpy(), \n",
    "              \"lmu =\", l_mu.data.numpy(), \n",
    "              \"lsigma =\", l_sigma.data.numpy(),\n",
    "              \"lnu =\", l_nu.data.numpy(),\n",
    "              \"dL/dlmu = \", l_mu.grad.data.numpy(), \n",
    "              \"dL/dlsigma = \", l_sigma.grad.data.numpy(),\n",
    "              \"dL/dlnu = \", l_nu.grad.data.numpy())\n",
    "    ## SGD update of parms\n",
    "    l_mu.data -= learning_rate_mu * l_mu.grad.data\n",
    "    l_sigma.data -= learning_rate_sigma * l_sigma.grad.data\n",
    "    l_nu.data -= learning_rate_nu * l_nu.grad.data\n",
    "    ## Zero the gradients\n",
    "    l_mu.grad.data.zero_()\n",
    "    l_sigma.grad.data.zero_()\n",
    "    l_nu.grad.data.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENmhqPFPwEHS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "## Print session info to console \n",
    "########################\n",
    "sinfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP+Y2qdOHz9LLr9FTwsBagp",
   "collapsed_sections": [],
   "name": "PyTorch_CountDistMLEs_SpeciesDatasetExample.ipynb",
   "provenance": [
    {
     "file_id": "1XRwZ_jQyySdAa4a4jZ7VwYuLWtRaz4f2",
     "timestamp": 1625988939591
    },
    {
     "file_id": "1Q-GUXkWcqMJjpF_OgecQBUA7ZEGBLkXw",
     "timestamp": 1625986377347
    },
    {
     "file_id": "1UVQOt_noxCtpcDVvyBz6GPuDTD3XPTCZ",
     "timestamp": 1625983790664
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
