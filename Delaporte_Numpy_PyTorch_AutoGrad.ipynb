{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1626061355643,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "siMpwITBI_fM"
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "## Numpy/PyTorch implementation of Delaporte Distribution\n",
    "## See: https://github.com/cran/gamlss.dist\n",
    "## See (count distributions - page197): http://www.gamlss.com/wp-content/uploads/2013/01/gamlss-manual.pdf \n",
    "##\n",
    "## Author: Chris Meaney\n",
    "## Date: August 2021\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3998,
     "status": "ok",
     "timestamp": 1626061359965,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "E4ozfC7PJCqf"
   },
   "outputs": [],
   "source": [
    "## Dependency modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.special import gammaln\n",
    "from sinfo import sinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "executionInfo": {
     "elapsed": 22643,
     "status": "ok",
     "timestamp": 1626061382604,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "wFUABrptfuuu",
    "outputId": "9b5d096e-a385-4108-c72f-5c04f0c3260d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fish</th>\n",
       "      <th>lake</th>\n",
       "      <th>x</th>\n",
       "      <th>scale_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>-1.533430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>-0.901903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>171</td>\n",
       "      <td>5.141664</td>\n",
       "      <td>-0.473281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113</td>\n",
       "      <td>25719</td>\n",
       "      <td>10.154985</td>\n",
       "      <td>1.031399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>59596</td>\n",
       "      <td>10.995344</td>\n",
       "      <td>1.283621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.016481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>-0.880708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114</td>\n",
       "      <td>58016</td>\n",
       "      <td>10.968474</td>\n",
       "      <td>1.275556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>112</td>\n",
       "      <td>19477</td>\n",
       "      <td>9.876990</td>\n",
       "      <td>0.947962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>-1.325392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>-0.683080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.016481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39</td>\n",
       "      <td>174</td>\n",
       "      <td>5.159055</td>\n",
       "      <td>-0.468061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>-1.686748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>3.988984</td>\n",
       "      <td>-0.819242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fish   lake          x   scale_x\n",
       "0     10      5   1.609438 -1.533430\n",
       "1     37     41   3.713572 -0.901903\n",
       "2     60    171   5.141664 -0.473281\n",
       "3    113  25719  10.154985  1.031399\n",
       "4     99  59596  10.995344  1.283621\n",
       "5     13      1   0.000000 -2.016481\n",
       "6     30     44   3.784190 -0.880708\n",
       "7    114  58016  10.968474  1.275556\n",
       "8    112  19477   9.876990  0.947962\n",
       "9     17     10   2.302585 -1.325392\n",
       "10    10     85   4.442651 -0.683080\n",
       "11    14      1   0.000000 -2.016481\n",
       "12    39    174   5.159055 -0.468061\n",
       "13    14      3   1.098612 -1.686748\n",
       "14    14     54   3.988984 -0.819242"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################################\n",
    "## Use pandas to import data, and store as DataFrame\n",
    "## Data are 1) response/target variable (number of fish = count random variable), 2) lake size (single continous feature/predictor)\n",
    "##########################################################\n",
    "dat = pd.read_csv('C://Users//ChristopherMeaney//Desktop//PyTorch_Stuff//pytorch_count_dists//species.csv', encoding='latin1')\n",
    "dat.head(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1626061382606,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "5-Hzlh2yJCvy",
    "outputId": "211689d5-e4ef-4c31-9aaa-25f0f8ef16ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     70.000000\n",
       "mean      41.742857\n",
       "std       47.849609\n",
       "min        5.000000\n",
       "25%       14.000000\n",
       "50%       21.500000\n",
       "75%       47.500000\n",
       "max      245.000000\n",
       "Name: fish, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Describe the data\n",
    "dat.fish.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.74285714285714"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_ = dat.fish.mean()\n",
    "mu_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.84960912241293"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_ = np.sqrt(dat.fish.var())\n",
    "sigma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1626061382607,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "TjFl0euzh5Vv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.90546511, -1.08778666, -1.8148354 , -2.76919808, -3.8186649 ,\n",
       "       -4.90299249, -5.99806526, -7.09592071, -8.19439115, -9.2929798 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################\n",
    "## Numpy implementation of Delaporte Loss/Density Function\n",
    "## Function is basically a Numpy implementation of Rigby et al gamlss.dist R Code (which calls tofyDEL2.c)\n",
    "## https://github.com/cran/gamlss.dist/tree/master/src/tofydel2.c\n",
    "###################################################\n",
    "def d_DEL_np(x, mu, sigma, nu, log=True): \n",
    "    ## Determine length of data vector and parameters \n",
    "    ly = np.max(np.array([len(x), len(mu), len(sigma), len(nu)]))  \n",
    "    #x = np.repeat(a=x, repeats=ly)      \n",
    "    nsigma = np.repeat(a=sigma, repeats=ly)\n",
    "    nmu = np.repeat(a=mu, repeats=ly)\n",
    "    nnu = np.repeat(a=nu, repeats=ly)\n",
    "    ## Initial vectors to store computed DEL density values\n",
    "    ny = int(len(x))\n",
    "    maxyp1 = np.max(x) + 1\n",
    "    tofY = np.zeros(shape=(maxyp1))\n",
    "    sumlty = np.zeros(shape=(ly))\n",
    "    ## Compute log-prob in instance that x=0 (note: this is just kernel of density, data does not enter equation)\n",
    "    logpy0 = -nmu*nnu-(1/nsigma)*(np.log(1+nmu*nsigma*(1-nnu)))\n",
    "    ## Big for loop to compute DEL density (or log-density)\n",
    "    ## This is directly from Rigby et al: tofyDEL2.c code.\n",
    "    for i in range(1, ny+1):\n",
    "        iy = x[i-1] + 1\n",
    "        tofY[0] = nmu[i-1] * nnu[i-1]+nmu[i-1]*(1-nnu[i-1])/(1+nmu[i-1] * nsigma[i-1]*(1-nnu[i-1]))\n",
    "        sumT = 0 \n",
    "        ## Start inner loop to compute rest of DEL density\n",
    "        if (x[i-1]==0):\n",
    "            sumT = 0\n",
    "        else:\n",
    "            for j in range(1, iy):\n",
    "                dum = 1 + (1/(nmu[i-1] * nsigma[i-1] * (1-nnu[i-1])))\n",
    "                tofY[j] = ( (j) + (nmu[i-1] * nnu[i-1]) + 1/(nsigma[i-1] * (1 - nnu[i-1])) - (nmu[i-1] * nnu[i-1] * (j))/tofY[j-1]) / dum\n",
    "                sumT = sumT + np.log(tofY[j-1])\n",
    "        sumlty[i-1] = sumT\n",
    "    ## Add the kernel of the DEL density back to other constant component\n",
    "    logfy = logpy0 - gammaln(x+1) + sumlty\n",
    "    ## log={T,F} flag: T=return log-density; F=return density\n",
    "    if(log==False):\n",
    "        fy = np.exp(logfy)\n",
    "    else:\n",
    "        fy = logfy\n",
    "    ## Return log density function to user\n",
    "    return fy\n",
    "\n",
    "d_DEL_np(x=np.arange(10), mu=np.array([1]), sigma=np.array([1]), nu=np.array([0.5]), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9055, -1.0878, -1.8148, -2.7692, -3.8187, -4.9030, -5.9981, -7.0959,\n",
       "        -8.1944, -9.2930])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################\n",
    "## PyTorch implementation of Delaporte Loss/Density Function\n",
    "## Function is basically a Numpy implementation of Rigby et al gamlss.dist R Code (which calls tofyDEL2.c)\n",
    "## https://github.com/cran/gamlss.dist/tree/master/src/tofydel2.c\n",
    "###################################################\n",
    "def d_DEL_th(x, mu, sigma, nu, log=True): \n",
    "    ## Determine length of data vector and parameters \n",
    "    ly = int(torch.max(torch.Tensor([len(x), len(mu), len(sigma), len(nu)])).item())\n",
    "    #x = np.repeat(a=x, repeats=ly)      \n",
    "    nsigma = sigma.repeat(ly)\n",
    "    nmu = mu.repeat(ly)\n",
    "    nnu = nu.repeat(ly)\n",
    "    ## Initial vectors to store computed DEL density values\n",
    "    ny = int(len(x))\n",
    "    maxyp1 = x.max().item() + 1\n",
    "    tofY = torch.zeros(int(maxyp1))\n",
    "    sumlty = torch.zeros(ly)\n",
    "    ## Compute log-prob in instance that x=0 (note: this is just kernel of density, data does not enter equation)\n",
    "    logpy0 = -nmu*nnu-(1/nsigma)*(torch.log(1+nmu*nsigma*(1-nnu)))\n",
    "    ## Big for loop to compute DEL density (or log-density)\n",
    "    ## This is directly from Rigby et al: tofyDEL2.c code.\n",
    "    for i in torch.arange(1, ny+1):\n",
    "        iy = x[i.item()-1] + 1\n",
    "        tofY[0] = nmu[i.item()-1] * nnu[i.item()-1]+nmu[i.item()-1]*(1-nnu[i.item()-1])/(1+nmu[i.item()-1] * nsigma[i.item()-1]*(1-nnu[i.item()-1]))\n",
    "        sumT = 0 \n",
    "        ## Start inner loop to compute rest of DEL density\n",
    "        if (x[i.item()-1]==0):\n",
    "            sumT = 0\n",
    "        else:\n",
    "            for j in torch.arange(1, iy):\n",
    "                dum = 1 + (1/(nmu[i.item()-1] * nsigma[i.item()-1] * (1-nnu[i.item()-1])))\n",
    "                tofY[j.item()] = ( (j) + (nmu[i.item()-1] * nnu[i.item()-1]) + 1/(nsigma[i.item()-1] * (1 - nnu[i.item()-1])) - (nmu[i.item()-1] * nnu[i.item()-1] * (j))/tofY[j.item()-1]) / dum\n",
    "                sumT = sumT + torch.log(tofY[j.item()-1])\n",
    "        sumlty[i.item()-1] = sumT\n",
    "    ## Add the kernel of the DEL density back to other constant component\n",
    "    logfy = logpy0 - torch.lgamma(x+1) + sumlty\n",
    "    ## log={T,F} flag: T=return log-density; F=return density\n",
    "    if(log==False):\n",
    "        fy = torch.exp(logfy)\n",
    "    else:\n",
    "        fy = logfy\n",
    "    ## Return log density function to user\n",
    "    return fy\n",
    "\n",
    "d_DEL_th(x=torch.arange(10), mu=torch.Tensor([1]), sigma=torch.Tensor([1]), nu=torch.Tensor([0.5]), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WARNING: read me... \n",
    "## Below is user-defined R implementation of Delaporte density\n",
    "## We also compare against gamlss.dist::dDEL() code rolled out in gamlss.dist package\n",
    "## Documentation on page 197: http://www.gamlss.com/wp-content/uploads/2013/01/gamlss-manual.pdf\n",
    "## You will see that above Numpy and PyTorch implementations agree with R output (up to many decimal places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "> ########################################################\n",
    "> ## Delaporte Distribution\n",
    "> ########################################################\n",
    "> d_DEL <- function(x, mu=1, sigma=1, nu=0.5, log=FALSE) {\n",
    "+     ## Warning messages on paramter and data space constraint violations\n",
    "+     if (any(mu <= 0) )  stop(paste(\"mu must be greater than 0 \", \"\\n\", \"\")) \n",
    "+     if (any(sigma <= 0) )  stop(paste(\"sigma must be greater than 0 \", \"\\n\", \"\")) \n",
    "+     if (any(nu <= 0) | any(nu >= 1))  stop(paste(\"nu must be between 0 and 1\", \"\\n\", \"\")) \n",
    "+     if (any(x < 0) )  stop(paste(\"x must be >=0\", \"\\n\", \"\"))\n",
    "+     ## Determine length of data vector and parameters \n",
    "+     ly <- max(length(x), length(mu), length(sigma), length(nu)) \n",
    "+     x <- rep(x, length=ly)      \n",
    "+     nsigma <- rep(sigma, length=ly)\n",
    "+     nmu <- rep(mu, length=ly)   \n",
    "+     nnu <- rep(nu, length=ly) \n",
    "+     ## Initial vectors to store computed DEL density values\n",
    "+     ny <- as.integer(length(x))\n",
    "+     maxyp1 <- max(x) + 1\n",
    "+     tofY <- rep(NA_real_, maxyp1)\n",
    "+     sumlty <- rep(NA_real_, ly)\n",
    "+     ## Compute log-prob in instance that x=0 (note: this is just kernel of density, data does not enter equation)\n",
    "+     logpy0 <- -nmu*nnu-(1/nsigma)*(log(1+nmu*nsigma*(1-nnu)))\n",
    "+     ## Big for loop to compute DELAPORTE density (or log-density)\n",
    "+     ## This is directly from Rigby et al: tofyDEL2.c code.\n",
    "+     for (i in 1:ny) {\n",
    "+         iy <- x[i] + 1\n",
    "+         tofY[1] <- nmu[i] * nnu[i]+nmu[i]*(1-nnu[i])/(1+nmu[i] * nsigma[i]*(1-nnu[i]))\n",
    "+         sumT <- 0 \n",
    "+         ## Start inner loop to compute rest of DEL density\n",
    "+         if (x[i]==0) {\n",
    "+             sumT <- 0\n",
    "+         } else {\n",
    "+             for (j in 1:(iy-1)) {\n",
    "+                 dum = 1 + (1/(nmu[i] * nsigma[i] * (1-nnu[i])))\n",
    "+                 tofY[j + 1] <- ( (j) + (nmu[i] * nnu[i]) + 1/(nsigma[i] * (1 - nnu[i])) - (nmu[i] * nnu[i] * (j))/tofY[j]) / dum\n",
    "+                 sumT <- sumT + log(tofY[j])\n",
    "+             }\n",
    "+         }\n",
    "+         sumlty[i] <- sumT\n",
    "+     }\n",
    "+     ## Add the kernel of the DEL density back to other constant component\n",
    "+     logfy <-  logpy0 - lgamma(x+1) + sumlty\n",
    "+     ## Log={T,F} flag: T=return log-density; F=return density\n",
    "+     if(log==FALSE) {\n",
    "+         fy <- exp(logfy)  \n",
    "+     } else {\n",
    "+         fy <- logfy\n",
    "+     }\n",
    "+     ## Further exception handling for whether sigma<0.0001 (small) ==> in these cases, DEL can be approx. by POIS\n",
    "+     fy <- ifelse(nsigma>0.0001, fy, dpois(x, lambda=mu, log=log)) \n",
    "+     ## Return density to user\n",
    "+     return(fy)\n",
    "+ } \n",
    "\n",
    "> d_DEL(x=0:9, mu=1, sigma=1, nu=0.5, log=TRUE)\n",
    " [1]  -0.9054651  -1.0877867  -1.8148354  -2.7691981  -3.8186649  -4.9029925  -5.9980653  -7.0959207  -8.1943912  -9.2929798\n",
    "\n",
    "> dDEL(x=0:9, mu=1, sigma=1, nu=0.5, log=TRUE)\n",
    " [1]  -0.9054651  -1.0877867  -1.8148354  -2.7691981  -3.8186649  -4.9029925  -5.9980653  -7.0959207  -8.1943912  -9.2929798\n",
    "\n",
    "'''\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1626061408611,
     "user": {
      "displayName": "Christopher Meaney",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKFFOwHDdeq1jGbaX8XCVSLMIXialpqKx1BEbX=s64",
      "userId": "15619654579218208651"
     },
     "user_tz": 240
    },
    "id": "t3dvWeX3iUgR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JnSaWekcwDgo"
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Delaporte Model - try to learn MLE of fish count data; via AutoGrad/SGD implementation in PyTorch\n",
    "############################################## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nq4R0s7zwDkI"
   },
   "outputs": [],
   "source": [
    "## Instantiate data tensor, and variable for (binomial) model parameters\n",
    "x = torch.autograd.Variable(torch.from_numpy(dat.fish.to_numpy())).type(torch.FloatTensor)\n",
    "l_mu = torch.autograd.Variable(torch.rand(1), requires_grad=True)\n",
    "l_sigma = torch.autograd.Variable(torch.rand(1), requires_grad=True) \n",
    "l_nu = torch.autograd.Variable(torch.rand(1), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "R93ZSIclwDmq"
   },
   "outputs": [],
   "source": [
    "def del_nll(x, mu, sigma, nu): \n",
    "    ## Determine length of data vector and parameters \n",
    "    ly = int(torch.max(torch.Tensor([len(x), len(mu), len(sigma), len(nu)])).item())\n",
    "    #x = np.repeat(a=x, repeats=ly)      \n",
    "    nsigma = sigma.repeat(ly)\n",
    "    nmu = mu.repeat(ly)\n",
    "    nnu = nu.repeat(ly)\n",
    "    ## Initial vectors to store computed DEL density values\n",
    "    ny = int(len(x))\n",
    "    maxyp1 = x.max().item() + 1\n",
    "    tofY = torch.zeros(int(maxyp1))\n",
    "    sumlty = torch.zeros(ly)\n",
    "    ## Compute log-prob in instance that x=0 (note: this is just kernel of density, data does not enter equation)\n",
    "    logpy0 = -nmu*nnu-(1/nsigma)*(torch.log(1+nmu*nsigma*(1-nnu)))\n",
    "    ## Big for loop to compute DEL density (or log-density)\n",
    "    ## This is directly from Rigby et al: tofyDEL2.c code.\n",
    "    for i in torch.arange(1, ny+1):\n",
    "        iy = x[int(i.item()-1)] + 1\n",
    "        tofY[0] = nmu[int(i.item()-1)] * nnu[int(i.item()-1)]+nmu[int(i.item()-1)]*(1-nnu[int(i.item()-1)])/(1+nmu[int(i.item()-1)] * nsigma[int(i.item()-1)]*(1-nnu[int(i.item()-1)]))\n",
    "        sumT = 0 \n",
    "        ## Start inner loop to compute rest of DEL density\n",
    "        if (x[int(i.item()-1)]==0):\n",
    "            sumT = 0\n",
    "        else:\n",
    "            for j in torch.arange(1, iy):\n",
    "                dum = 1 + (1/(nmu[int(i.item()-1)] * nsigma[int(i.item()-1)] * (1-nnu[int(i.item()-1)])))\n",
    "                tofY[int(j.item())] = ( (j) + (nmu[int(i.item()-1)] * nnu[int(i.item()-1)]) + 1/(nsigma[int(i.item()-1)] * (1 - nnu[int(i.item()-1)])) - (nmu[int(i.item()-1)] * nnu[int(i.item()-1)] * (j))/tofY[int(j.item()-1)]) / dum\n",
    "                sumT = sumT + torch.log(tofY[int(j.item()-1)])\n",
    "        sumlty[int(i.item()-1)] = sumT\n",
    "    ## Add the kernel of the DEL density back to other constant component\n",
    "    logfy = logpy0 - torch.lgamma(x+1) + sumlty\n",
    "    ## Return neg log lik to user\n",
    "    nll = -torch.sum(logfy)\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9M2nPfBZwR0h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\autograd\\__init__.py:147: UserWarning: Error detected in DivBackward0. Traceback of forward call that caused the error:\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n",
      "    runner = Runner(ctx_run, result, future, yielded)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n",
      "    self.ctx_run(self.run)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2898, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3169, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\ChristopherMeaney\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-1e2c4b3c2e6e>\", line 11, in <module>\n",
      "    NLLdel = del_nll(x=x, mu=l_mu, sigma=l_sigma, nu=l_nu)\n",
      "  File \"<ipython-input-13-9f3ec4844d3a>\", line 27, in del_nll\n",
      "    tofY[int(j.item())] = ( (j) + (nmu[int(i.item()-1)] * nnu[int(i.item()-1)]) + 1/(nsigma[int(i.item()-1)] * (1 - nnu[int(i.item()-1)])) - (nmu[int(i.item()-1)] * nnu[int(i.item()-1)] * (j))/tofY[int(j.item()-1)]) / dum\n",
      " (Triggered internally at  ..\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of SelectBackward, is at version 2992; expected version 2991 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1e2c4b3c2e6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m## Backprop on negative log likelihood loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mNLLdel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdel_nll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml_mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml_sigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml_nu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mNLLdel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m## Logging to console\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of SelectBackward, is at version 2992; expected version 2991 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "## Learning rate\n",
    "learning_rate_mu = 2e-5\n",
    "learning_rate_sigma = 2e-5\n",
    "learning_rate_nu = 2e-5\n",
    "\n",
    "## Training loop\n",
    "for t in range(25000):\n",
    "    ## Backprop on negative log likelihood loss\n",
    "    NLLdel = del_nll(x=x, mu=l_mu, sigma=l_sigma, nu=l_nu) \n",
    "    NLLdel.backward()\n",
    "    ## Logging to console\n",
    "    if t % 1000 == 0:\n",
    "        print(\"Iteration = \", t, \n",
    "              \"loglik  =\", NLLpig.data.numpy(), \n",
    "              \"lmu =\", l_mu.data.numpy(), \n",
    "              \"lsigma =\", l_sigma.data.numpy(),\n",
    "              \"lnu =\", l_nu.data.numpy(),  \n",
    "              \"dL/dlmu = \", l_mu.grad.data.numpy(), \n",
    "              \"dL/dlsigma = \", l_sigma.grad.data.numpy(),\n",
    "              \"dL/dlnu = \", l_nu.grad.data.numpy()\n",
    "             )\n",
    "    ## SGD update of parms\n",
    "    l_mu.data -= learning_rate_mu * l_mu.grad.data\n",
    "    l_sigma.data -= learning_rate_sigma * l_sigma.grad.data\n",
    "    l_nu.data -= learning_rate_nu * l_nu.grad.data\n",
    "    ## Zero the gradients\n",
    "    l_mu.grad.data.zero_()\n",
    "    l_sigma.grad.data.zero_()\n",
    "    l_nu.grad.data.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENmhqPFPwEHS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "## Print session info to console \n",
    "########################\n",
    "sinfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP+Y2qdOHz9LLr9FTwsBagp",
   "collapsed_sections": [],
   "name": "PyTorch_CountDistMLEs_SpeciesDatasetExample.ipynb",
   "provenance": [
    {
     "file_id": "1XRwZ_jQyySdAa4a4jZ7VwYuLWtRaz4f2",
     "timestamp": 1625988939591
    },
    {
     "file_id": "1Q-GUXkWcqMJjpF_OgecQBUA7ZEGBLkXw",
     "timestamp": 1625986377347
    },
    {
     "file_id": "1UVQOt_noxCtpcDVvyBz6GPuDTD3XPTCZ",
     "timestamp": 1625983790664
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
